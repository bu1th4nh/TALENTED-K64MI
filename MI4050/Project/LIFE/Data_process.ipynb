{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX82dgiR77qy"
      },
      "outputs": [],
      "source": [
        "# /*==========================================================================================*\\\n",
        "# **                        _           _ _   _     _  _         _                            **\n",
        "# **                       | |__  _   _/ | |_| |__ | || |  _ __ | |__                         **\n",
        "# **                       | '_ \\| | | | | __| '_ \\| || |_| '_ \\| '_ \\                        **\n",
        "# **                       | |_) | |_| | | |_| | | |__   _| | | | | | |                       **\n",
        "# **                       |_.__/ \\__,_|_|\\__|_| |_|  |_| |_| |_|_| |_|                       **\n",
        "# \\*==========================================================================================*/\n",
        "\n",
        "\n",
        "# Author: Bùi Tiến Thành (@bu1th4nh)\n",
        "# Date: 2022/12/26 14:13 \n",
        "# CTTN Toán tin K64\n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import statsmodels.api as sm\n",
        "%matplotlib inline\n",
        "import os\n",
        "import re\n",
        "import ujson as json\n",
        "import os\n",
        "import ot\n",
        "from dtaidistance import dtw\n",
        "\n",
        "# Figure size\n",
        "height = 20\n",
        "width  = 8"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input, Resample and Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Ariel = pd.read_parquet(\"../DataWater_train_cleansed_phase3.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ariel.head()\n",
        "Belle = Ariel.copy().resample('D').mean().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes  = Ariel.columns\n",
        "mean        = Ariel.describe().loc[\"mean\", :].to_numpy()\n",
        "std         = Ariel.describe().loc[\"std\", :].to_numpy()\n",
        "D           = len(attributes)\n",
        "T           = len(Ariel)\n",
        "\n",
        "print(\"Mean: \", mean);\n",
        "print(\"Std:  \", std);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Do data được đo theo giờ nên ta có thể chuyển qua thời gian tương đối\n",
        "initial_time = Ariel.index[0];\n",
        "Ariel.reset_index(drop=True, inplace=True)\n",
        "for i, col in enumerate(Ariel.columns):\n",
        "    Ariel[col] = Ariel[col].apply(lambda x: (x - mean[i]) / std[i])\n",
        "\n",
        "timestamp = range(Ariel.shape[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Xây dựng ma trận đánh dấu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask = ~pd.isnull(Ariel)\n",
        "display(mask.head(5))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Xây dựng ma trận delta dựa theo lags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Số lượng mốc thời gian dùng để dự báo\n",
        "n_steps  = 96;\n",
        "\n",
        "# Danh sách các bộ (start, end) với data lấy từ start->end-1 và data dự báo là end\n",
        "idx_list = [];\n",
        "\n",
        "for i in tqdm(range(T - n_steps), desc=\"Building delta and samples\"):\n",
        "    # Lấy khoảng thời gian\n",
        "    (start, end) = (i, i + n_steps)\n",
        "\n",
        "    # Xây dựng delta\n",
        "    delta = np.zeros((n_steps, D))\n",
        "    for i in range(1, n_steps):\n",
        "        delta[i, :] = timestamp[start+i] - timestamp[start+i-1] + delta[i-1, :] * mask.iloc[start+i-1, :].astype(int).to_numpy();\n",
        "    delta = pd.DataFrame(delta, columns=attributes)\n",
        "\n",
        "    # Thêm vào danh sách\n",
        "    idx_list.append((start, end, delta))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Xây dựng ma trận HSTQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p_list = [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 10, 100]\n",
        "for epoch in range(len(p_list)):\n",
        "    df_null = None\n",
        "    df_dtw = None\n",
        "    df_dtw_f = None\n",
        "    penalty = p_list[epoch]\n",
        "    print('p:{}'.format(penalty))\n",
        "    w = None\n",
        "    length = n_steps\n",
        "\n",
        "    for i in tqdm(range(len(idx_list)), desc=f\"Processing idx_list with p={penalty}\"):\n",
        "        # if i % 20 == 0:\n",
        "        #     print('Processing {} of {}'.format(i, len(idx_list)))\n",
        "\n",
        "        (start, end, df_deltas) = idx_list[i]\n",
        "        df_mask                 = mask.loc[start:end]\n",
        "        df_values               = Ariel.loc[start:end].copy()\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "        df_values[~df_mask.astype(bool)] = np.nan\n",
        "        df_values.interpolate(method='linear', axis=0, inplace=True)\n",
        "        df_values.fillna(0, inplace=True)\n",
        "        distance = dtw.distance_matrix_fast(df_values.to_numpy().astype(float).swapaxes(1,0))\n",
        "\n",
        "\n",
        "        num = df_mask.sum()\n",
        "        miss_num = (df_deltas * (1-df_mask)).sum()\n",
        "        miss_num = np.tile(miss_num, (35,1))\n",
        "        penalty_matrix = miss_num + miss_num.transpose()\n",
        "\n",
        "\n",
        "        distance += penalty_matrix * penalty\n",
        "\n",
        "        num = np.tile(num, (35,1))\n",
        "        w_matrix = (num + num.transpose())/(2*length)\n",
        "\n",
        "\n",
        "        if df_dtw is not None:\n",
        "            df_dtw += distance * w_matrix\n",
        "            w += w_matrix\n",
        "        else:\n",
        "            df_dtw = distance * w_matrix\n",
        "            w = w_matrix\n",
        "            \n",
        "\n",
        "    inf_idx = np.isinf(df_dtw)\n",
        "    df_dtw[inf_idx] = 0\n",
        "    nan_idx = np.isnan(df_dtw)\n",
        "    df_dtw[nan_idx] = 0\n",
        "\n",
        "    df_dtw = df_dtw/(w+1e-5)\n",
        "\n",
        "    df_dtw += df_dtw.transpose()\n",
        "    df_dtw[np.where(np.eye(df_dtw.shape[0],dtype=bool))] += np.min(df_dtw[np.where(~np.eye(df_dtw.shape[0],dtype=bool))])\n",
        "\n",
        "\n",
        "\n",
        "    def normalization(data):\n",
        "        _range = np.max(data) - np.min(data)\n",
        "        return (data - np.min(data)) / _range\n",
        "\n",
        "\n",
        "    # plt.figure()\n",
        "    # sns.heatmap(abs(w), cmap='Reds')\n",
        "    # plt.close()\n",
        "\n",
        "    # df_dtw_exp = normalization(np.exp(-df_dtw))\n",
        "    # plt.figure()\n",
        "    # sns.heatmap(abs(df_dtw_exp), cmap='Reds')\n",
        "    # plt.savefig('../../../docs/figures/LPDTW/simple/p_'+str(penalty)+'.png')\n",
        "    # plt.close()\n",
        "\n",
        "    df_dtw_inv = normalization(1/df_dtw)\n",
        "    column_names = [i for i in range(1,36)]\n",
        "    df_dtw_inv = pd.DataFrame(df_dtw_inv, columns=column_names, index=column_names)\n",
        "    plt.figure()\n",
        "    sns.heatmap(abs(df_dtw_inv), cmap='Reds')\n",
        "\n",
        "\n",
        "    # plt.savefig('../../../docs/figures/POT/p_inv_' + str(penalty) + '.eps', format='eps', dpi=300, bbox_inches='tight')\n",
        "    # plt.savefig('figures/PDTW/p_' + str(penalty) + '.png', format='png', bbox_inches='tight')\n",
        "    # plt.close()\n",
        "\n",
        "    # np.savetxt('../data/POT_exp_' + str(penalty) + '.csv', df_ot_exp.to_numpy(), delimiter=',')\n",
        "    # np.savetxt('matrix/PDTW_' + str(penalty) + '.csv', df_dtw_inv.to_numpy(), delimiter=',')\n",
        "\n",
        "\n",
        "print('Done! Figures are saved to \\'{}\\', Correlation Matrices are saved to \\'{}\\''.format('figures/PDTW/','matrix/'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "VED",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ff0ecca3f77131a0f5c801cc132aefb4314682dcd2f82f452b6551c657e4ef8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
